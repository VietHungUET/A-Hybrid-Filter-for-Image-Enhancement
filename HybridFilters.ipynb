{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Filter for Image Enhancement\n",
    "\n",
    "This Jupyter Notebook implements a hybrid filter for image enhancement, as described in the paper *A Hybrid Filter for Image Enhancement* by Shaomin Peng and Lori Lucke. The filter removes mixed Gaussian and impulsive noise from color images while preserving details.\n",
    "\n",
    "## Filter Description\n",
    "- **Step 1: Selective Peeling**: Removes impulsive noise (e.g., salt-and-pepper) by replacing pixels that deviate significantly from the median in a local window with the median value.\n",
    "- **Step 2: Fuzzy Weighted Averaging**: Smooths Gaussian noise using a weighted average, with weights determined by a Gaussian-like fuzzy membership function based on pixel intensity differences.\n",
    "\n",
    "## Usage\n",
    "- **Prerequisites**:\n",
    "  - Install Jupyter Notebook: `pip install jupyter`\n",
    "  - Install dependencies: `pip install numpy matplotlib pillow ipywidgets`\n",
    "  - Enable widgets: `jupyter nbextension enable --py widgetsnbextension`\n",
    "  - For JupyterLab: `jupyter labextension install @jupyter-widgets/jupyterlab-manager`\n",
    "\n",
    "- **Notes**:\n",
    "  - If RGB histograms are identical (e.g., due to a grayscale image), Cell 8 will show high correlations (~1). Use Cell 5’s synthetic image or upload a colorful image.\n",
    "  - The filter processes RGB channels separately to preserve color and does not use training data.\n",
    "  - For best results, use images with mixed Gaussian and impulsive noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Install Dependencies\n",
    "# Purpose: Ensures required packages are installed (uncomment to run if needed).\n",
    "# !pip install numpy matplotlib pillow ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "##### Purpose: Imports libraries for array operations, plotting, image handling, and interactive widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:15:30.358177Z",
     "iopub.status.busy": "2025-04-20T08:15:30.357509Z",
     "iopub.status.idle": "2025-04-20T08:15:30.414371Z",
     "shell.execute_reply": "2025-04-20T08:15:30.413777Z",
     "shell.execute_reply.started": "2025-04-20T08:15:30.358155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "from IPython.display import display, clear_output\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Hybrid Filter Function\n",
    "##### Purpose: Implements the hybrid filter to remove mixed Gaussian and impulsive noise from color images.\n",
    "- Step 1: Selective Peeling (removes impulsive noise using median replacement).\n",
    "- Step 2: Fuzzy Weighted Averaging (smooths Gaussian noise with Gaussian-like weights).\n",
    "- Processes RGB channels separately to preserve color.\n",
    "- Optionally returns the peeled image for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:59:51.876149Z",
     "iopub.status.busy": "2025-04-20T07:59:51.875488Z",
     "iopub.status.idle": "2025-04-20T07:59:51.885104Z",
     "shell.execute_reply": "2025-04-20T07:59:51.884473Z",
     "shell.execute_reply.started": "2025-04-20T07:59:51.876127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def hybrid_filter(image, window_size=3, threshold=50, sigma=30, return_peeled=False):\n",
    "    \"\"\"\n",
    "    Apply the hybrid filter to remove mixed Gaussian and impulsive noise.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: Input noisy image (H x W x 3 numpy array, RGB).\n",
    "    - window_size: Size of the local neighborhood (3, 5, or 7).\n",
    "    - threshold: Threshold for detecting impulsive noise.\n",
    "    - sigma: Parameter for the Gaussian-like fuzzy weight function.\n",
    "    - return_peeled: If True, return the peeled image (after Step 1).\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_image: Filtered image (H x W x 3 numpy array).\n",
    "    - peeled_image: Peeled image (H x W x 3 numpy array, optional).\n",
    "    \"\"\"\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "    N = window_size // 2\n",
    "    \n",
    "    height, width, channels = image.shape\n",
    "    peeled_image = np.copy(image).astype(np.float64)\n",
    "    filtered_image = np.zeros_like(image, dtype=np.float64)\n",
    "    \n",
    "    # Step 1: Selective Peeling\n",
    "    for channel in range(channels):\n",
    "        for y in range(N, height - N):\n",
    "            for x in range(N, width - N):\n",
    "                window = image[y-N:y+N+1, x-N:x+N+1, channel]\n",
    "                median_val = np.median(window)\n",
    "                center_val = image[y, x, channel]\n",
    "                if abs(center_val - median_val) > threshold:\n",
    "                    peeled_image[y, x, channel] = median_val\n",
    "    \n",
    "    # Step 2: Fuzzy Weighted Averaging\n",
    "    for channel in range(channels):\n",
    "        for y in range(N, height - N):\n",
    "            for x in range(N, width - N):\n",
    "                window = peeled_image[y-N:y+N+1, x-N:x+N+1, channel]\n",
    "                center_val = peeled_image[y, x, channel]\n",
    "                weights = np.zeros((window_size, window_size))\n",
    "                for j in range(window_size):\n",
    "                    for i in range(window_size):\n",
    "                        delta = abs(center_val - window[j, i])\n",
    "                        weights[j, i] = np.exp(-delta**2 / (2 * sigma**2))\n",
    "                weighted_sum = np.sum(weights * window)\n",
    "                weight_total = np.sum(weights)\n",
    "                filtered_image[y, x, channel] = weighted_sum / weight_total if weight_total > 0 else center_val\n",
    "    \n",
    "    # Handle borders\n",
    "    filtered_image[:N, :, :] = peeled_image[:N, :, :]\n",
    "    filtered_image[-N:, :, :] = peeled_image[-N:, :, :]\n",
    "    filtered_image[:, :N, :] = peeled_image[:, :N, :]\n",
    "    filtered_image[:, -N:, :] = peeled_image[:, -N:, :]\n",
    "    \n",
    "    filtered_image = np.clip(filtered_image, 0, 255).astype(np.uint8)\n",
    "    if return_peeled:\n",
    "        peeled_image = np.clip(peeled_image, 0, 255).astype(np.uint8)\n",
    "        return filtered_image, peeled_image\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Interactive Interface\n",
    "##### Purpose: Sets up widgets for uploading an image and specifying filter parameters.\n",
    "- Stores image and parameters in global variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T07:59:56.930523Z",
     "iopub.status.busy": "2025-04-20T07:59:56.929842Z",
     "iopub.status.idle": "2025-04-20T07:59:56.948936Z",
     "shell.execute_reply": "2025-04-20T07:59:56.948147Z",
     "shell.execute_reply.started": "2025-04-20T07:59:56.930501Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bf279f9bc14396b90860354aa4fb0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='image/*', description='Upload Image'), Dropdown(description='Windo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Global variables\n",
    "global_image = None  # Reset to allow synthetic image or upload\n",
    "global_window_size = 3\n",
    "global_threshold = 50\n",
    "global_sigma = 30\n",
    "\n",
    "def create_interactive_filter():\n",
    "    upload = widgets.FileUpload(accept='image/*', multiple=False, description='Upload Image')\n",
    "    window_size = widgets.Dropdown(options=[3, 5, 7], value=3, description='Window Size:')\n",
    "    threshold = widgets.IntSlider(min=10, max=100, value=50, description='Threshold:')\n",
    "    sigma = widgets.IntSlider(min=10, max=100, value=30, description='Sigma:')\n",
    "    apply_button = widgets.Button(description='Apply Filter', button_style='primary')\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    display(widgets.VBox([upload, window_size, threshold, sigma, apply_button, output]))\n",
    "    \n",
    "    def on_apply_button_clicked(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            if not upload.value:\n",
    "                print('Please upload an image first!')\n",
    "                return\n",
    "            uploaded_file = upload.value[0]\n",
    "            image = Image.open(io.BytesIO(uploaded_file['content']))\n",
    "            image = np.array(image.convert('RGB'))\n",
    "            global global_image, global_window_size, global_threshold, global_sigma\n",
    "            global_image = image\n",
    "            global_window_size = window_size.value\n",
    "            global_threshold = threshold.value\n",
    "            global_sigma = sigma.value\n",
    "            print('Image uploaded. Run the next cells to apply the filter.')\n",
    "    \n",
    "    apply_button.on_click(on_apply_button_clicked)\n",
    "\n",
    "create_interactive_filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 7: Apply Filter and Display Images\n",
    "##### Purpose: Applies the hybrid filter using the uploaded or synthetic image and parameters.\n",
    "- Displays original, peeled, and filtered images in a 1x3 subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:00:10.416891Z",
     "iopub.status.busy": "2025-04-20T08:00:10.416638Z",
     "iopub.status.idle": "2025-04-20T08:00:10.422364Z",
     "shell.execute_reply": "2025-04-20T08:00:10.421728Z",
     "shell.execute_reply.started": "2025-04-20T08:00:10.416873Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please run Cell 5 to generate a synthetic image or Cell 6 to upload an image first!\n"
     ]
    }
   ],
   "source": [
    "if global_image is None:\n",
    "    print('Please run Cell 5 to generate a synthetic image or Cell 6 to upload an image first!')\n",
    "else:\n",
    "    filtered_image, peeled_image = hybrid_filter(\n",
    "        global_image, global_window_size, global_threshold, global_sigma, return_peeled=True\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(global_image)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(peeled_image)\n",
    "    plt.title('Peeled Image (Step 1)')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(filtered_image)\n",
    "    plt.title('Filtered Image (Step 2)')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Histograms and Difference Image\n",
    "##### Purpose: Analyzes the filter's effect using histograms and a difference image.\n",
    "- Histograms: Plots RGB channel intensities for original and filtered images.\n",
    "- Difference Image: Shows |original - filtered| to highlight noise removal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:00:14.311308Z",
     "iopub.status.busy": "2025-04-20T08:00:14.311043Z",
     "iopub.status.idle": "2025-04-20T08:00:14.317325Z",
     "shell.execute_reply": "2025-04-20T08:00:14.316556Z",
     "shell.execute_reply.started": "2025-04-20T08:00:14.311288Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please run the previous cells to generate or upload an image and apply the filter first!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if global_image is None or 'filtered_image' not in locals():\n",
    "    print('Please run the previous cells to generate or upload an image and apply the filter first!')\n",
    "else:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = ['Red', 'Green', 'Blue']\n",
    "    for i, color in enumerate(colors):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.hist(global_image[:, :, i].ravel(), bins=100, color='gray', alpha=0.5, label='Original', density=False)\n",
    "        plt.hist(filtered_image[:, :, i].ravel(), bins=100, color='blue', alpha=0.5, label='Filtered', density=False)\n",
    "        plt.title(f'{color} Channel Histogram')\n",
    "        plt.xlabel('Pixel Intensity')\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:00:18.046263Z",
     "iopub.status.busy": "2025-04-20T08:00:18.045883Z",
     "iopub.status.idle": "2025-04-20T08:00:18.054803Z",
     "shell.execute_reply": "2025-04-20T08:00:18.053662Z",
     "shell.execute_reply.started": "2025-04-20T08:00:18.046230Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please run the previous cells to generate or upload an image and apply the filter first!\n"
     ]
    }
   ],
   "source": [
    "if global_image is None or 'filtered_image' not in locals():\n",
    "    print('Please run the previous cells to generate or upload an image and apply the filter first!')\n",
    "else:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = ['Red', 'Green', 'Blue']\n",
    "    diff_image = np.abs(global_image.astype(np.float64) - filtered_image.astype(np.float64))\n",
    "    diff_image = np.mean(diff_image, axis=2)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(diff_image, cmap='hot')\n",
    "    plt.colorbar(label='Intensity Difference')\n",
    "    plt.title('Difference Image (Original - Filtered)')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize σ Using LMS\n",
    "##### Purpose: Learn the optimal parameter σ for the fuzzy Gaussian weighting function using the Least Mean Square (LMS) algorithm.\n",
    "- **Membership Function**: Uses Gaussian function $ w(\\Delta x') = \\exp\\left(-\\frac{(\\Delta x')^2}{2\\sigma^2}\\right) $ to assign weights.\n",
    "- **Training Data**: Each 3×3 window from the image is used to compute weights and compare with desired values.\n",
    "- **LMS Update Rule**: σ is adjusted iteratively to minimize the total squared error between the computed and desired memberships.\n",
    "\n",
    "### Training Steps:\n",
    "1. Extract 3×3 windows from a training image (original or filtered).\n",
    "2. Compute $ \\Delta x_{i,j}' = x_{i,j}' - x_{m,n}' $ for each pixel in the window.\n",
    "3. Calculate fuzzy membership values for each neighbor using current σ.\n",
    "4. Compare with desired membership labels (1 for clean pixels, 0 for noisy).\n",
    "5. Compute error $ e_{i,j} = d_{i,j} - w(\\Delta x_{i,j}') $.\n",
    "6. Compute gradient of error with respect to σ.\n",
    "7. Update σ: $ \\sigma \\leftarrow \\sigma - \\eta \\cdot \\frac{\\partial E}{\\partial \\sigma} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T08:07:29.503232Z",
     "iopub.status.busy": "2025-04-20T08:07:29.502959Z",
     "iopub.status.idle": "2025-04-20T08:07:29.611148Z",
     "shell.execute_reply": "2025-04-20T08:07:29.610270Z",
     "shell.execute_reply.started": "2025-04-20T08:07:29.503212Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59595f4f2e84769a59e1ea02ff28089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='image/*', description='Upload Original Image'), FileUpload(value=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Global variables\n",
    "global_original_image = None\n",
    "global_noisy_image = None\n",
    "global_window_size = 3\n",
    "global_threshold = 50\n",
    "global_sigma = 30\n",
    "\n",
    "def create_interactive_upload():\n",
    "    upload_original = widgets.FileUpload(accept='image/*', multiple=False, description='Upload Original Image')\n",
    "    upload_noisy = widgets.FileUpload(accept='image/*', multiple=False, description='Upload Noisy Image')\n",
    "    window_size = widgets.Dropdown(options=[3, 5, 7], value=3, description='Window Size:')\n",
    "    threshold = widgets.IntSlider(min=10, max=100, value=50, description='Threshold:')\n",
    "    sigma = widgets.IntSlider(min=10, max=100, value=30, description='Sigma:')\n",
    "    apply_button = widgets.Button(description='Apply Filter', button_style='primary')\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    display(widgets.VBox([upload_original, upload_noisy, window_size, threshold, sigma, apply_button, output]))\n",
    "    \n",
    "    def on_apply_button_clicked(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            if not upload_original.value or not upload_noisy.value:\n",
    "                print('Please upload both original and noisy images!')\n",
    "                return\n",
    "            original_file = upload_original.value[0]\n",
    "            noisy_file = upload_noisy.value[0]\n",
    "            original_image = Image.open(io.BytesIO(original_file['content']))\n",
    "            noisy_image = Image.open(io.BytesIO(noisy_file['content']))\n",
    "            original_image = np.array(original_image.convert('RGB'))\n",
    "            noisy_image = np.array(noisy_image.convert('RGB'))\n",
    "            global global_original_image, global_noisy_image, global_window_size, global_threshold, global_sigma\n",
    "            global_original_image = original_image\n",
    "            global_noisy_image = noisy_image\n",
    "            global_window_size = window_size.value\n",
    "            global_threshold = threshold.value\n",
    "            global_sigma = sigma.value\n",
    "            print('Images uploaded. Run the next cells to apply the filter or optimize sigma.')\n",
    "    \n",
    "    apply_button.on_click(on_apply_button_clicked)\n",
    "\n",
    "create_interactive_upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T10:42:28.466165Z",
     "iopub.status.busy": "2025-04-20T10:42:28.465615Z",
     "iopub.status.idle": "2025-04-20T10:43:07.426033Z",
     "shell.execute_reply": "2025-04-20T10:43:07.425207Z",
     "shell.execute_reply.started": "2025-04-20T10:42:28.466142Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Sigma: 16.0084, MSE: 170.3844\n",
      "Iteration 50, Sigma: 16.4253, MSE: 167.5545\n",
      "Iteration 100, Sigma: 16.8329, MSE: 164.8760\n",
      "Iteration 150, Sigma: 17.2305, MSE: 162.3489\n",
      "Iteration 200, Sigma: 17.6181, MSE: 159.9666\n",
      "Iteration 250, Sigma: 17.9959, MSE: 157.7218\n",
      "Iteration 300, Sigma: 18.3641, MSE: 155.6070\n",
      "Iteration 350, Sigma: 18.7230, MSE: 153.6147\n",
      "Iteration 400, Sigma: 19.0728, MSE: 151.7374\n",
      "Iteration 450, Sigma: 19.4138, MSE: 149.9677\n",
      "Optimal Sigma: 19.7398\n"
     ]
    }
   ],
   "source": [
    "def hybrid_filter_pytorch(noisy_image, window_size=3, threshold=50, sigma=30):\n",
    "    \"\"\"\n",
    "    Apply the hybrid filter to remove mixed Gaussian and impulsive noise using PyTorch.\n",
    "    \n",
    "    Parameters:\n",
    "    - noisy_image: Input noisy image (torch tensor, H x W x 3).\n",
    "    - window_size: Size of the local neighborhood (3, 5, or 7).\n",
    "    - threshold: Threshold for detecting impulsive noise.\n",
    "    - sigma: Parameter for the Gaussian-like fuzzy weight function (torch tensor).\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_image: Filtered image (torch tensor, H x W x 3).\n",
    "    \"\"\"\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "    N = window_size // 2\n",
    "    \n",
    "    height, width, channels = noisy_image.shape\n",
    "    peeled_image = noisy_image.clone().to(dtype=torch.float32)\n",
    "    \n",
    "    # Step 1: Selective Peeling\n",
    "  \n",
    "    padded_image = F.pad(peeled_image.permute(2, 0, 1), (N, N, N, N), mode='reflect')  # Shape: (C, H+2N, W+2N)\n",
    "    \n",
    "    # Extract all windows using unfold\n",
    "    unfolded = padded_image.unsqueeze(0)  # Shape: (1, C, H+2N, W+2N)\n",
    "    patches = F.unfold(unfolded, kernel_size=window_size, stride=1)  # Shape: (1, C*window_size*window_size, num_patches)\n",
    "    num_patches = (height) * (width)\n",
    "    patches = patches.view(channels, window_size * window_size, num_patches)  # Shape: (C, window_size*window_size, num_patches)\n",
    "    \n",
    "    # Compute median for each window\n",
    "    median_vals = torch.median(patches, dim=1)[0]  # Shape: (C, num_patches)\n",
    "    median_vals = median_vals.view(channels, height, width).permute(1, 2, 0)  # Shape: (H, W, C)\n",
    "    \n",
    "    # Get center values (original pixel values at the center of each window)\n",
    "    center_vals = noisy_image  # Shape: (H, W, C)\n",
    "    \n",
    "    # Detect impulsive noise and replace with median\n",
    "    mask_impulsive = torch.abs(center_vals - median_vals) > threshold  # Shape: (H, W, C)\n",
    "    peeled_image = torch.where(mask_impulsive, median_vals, peeled_image)\n",
    "    \n",
    "    # Step 2: Fuzzy Weighted Averaging (vectorized)\n",
    "    # Add padding to handle borders\n",
    "   \n",
    "    peeled_image_batched = peeled_image.unsqueeze(0)\n",
    "    padded_peeled = F.pad(peeled_image_batched, (0,0,N,N,N,N), mode='reflect')  # Shape: (H+2N, W+2N, C)\n",
    "    padded_peeled = padded_peeled.squeeze(0)\n",
    "  \n",
    "    padded_height, padded_width, actual_channels = padded_peeled.shape\n",
    "  \n",
    "    # Extract all windows using unfold\n",
    "    unfolded = padded_peeled.permute(2, 0, 1).unsqueeze(0)  # Shape: (1, C, H+2N, W+2N)\n",
    "    patches = F.unfold(unfolded, kernel_size=window_size, stride=1)  # Shape: (1, C*window_size*window_size, num_patches)\n",
    "    num_patches = (padded_height - window_size + 1) * (padded_width - window_size + 1)\n",
    "  \n",
    "    patches = patches.view(channels, window_size * window_size, num_patches)  # Shape: (C, window_size*window_size, num_patches)\n",
    "    \n",
    "    # Get center values for each window\n",
    "    center_vals = patches[:, (window_size * window_size) // 2, :]  # Shape: (C, num_patches)\n",
    "    center_vals = center_vals.view(channels, 1, num_patches)  # Shape: (C, 1, num_patches)\n",
    "    \n",
    "    # Compute deltas and weights\n",
    "    deltas = torch.abs(patches - center_vals)  # Shape: (C, window_size*window_size, num_patches)\n",
    "    weights = torch.exp(-deltas**2 / (2 * sigma**2))  # Shape: (C, window_size*window_size, num_patches)\n",
    "    \n",
    "    # Compute weighted sum and total weight\n",
    "    weighted_sum = torch.sum(weights * patches, dim=1)  # Shape: (C, num_patches)\n",
    "    weight_total = torch.sum(weights, dim=1)  # Shape: (C, num_patches)\n",
    "    \n",
    "    # Compute filtered values\n",
    "    filtered_vals = weighted_sum / (weight_total + 1e-6)  # Shape: (C, num_patches)\n",
    "    filtered_vals = filtered_vals.view(channels, padded_height - window_size +1, padded_width- window_size +1)  # Shape: (C, H, W)\n",
    "    filtered_vals = filtered_vals.permute(1, 2, 0)  # Shape: (H, W, C)\n",
    "\n",
    "\n",
    "\n",
    "    # Đảm bảo kích thước chính xác\n",
    "    filtered_image = filtered_vals  # Shape: (256, 256, C)\n",
    "\n",
    "    # Handle cases where weight_total is 0\n",
    "    mask_zero_weight = (weight_total == 0).view(channels, padded_height - window_size + 1, padded_width - window_size + 1).permute(1, 2, 0)  # Shape: (254, 256, C)\n",
    "    # mask_zero_weight = F.pad(mask_zero_weight, (0, 0, N, N,N,N), mode='constant', value=0)  # Shape: (256, 256, C)\n",
    "    # mask_zero_weight = mask_zero_weight[:height, :width, :]  # Shape: (256, 256, C)\n",
    "    filtered_image = torch.where(mask_zero_weight, peeled_image, filtered_image)\n",
    "    \n",
    "   \n",
    "    # Handle borders\n",
    "    filtered_image[:N, :, :] = peeled_image[:N, :, :]\n",
    "    filtered_image[-N:, :, :] = peeled_image[-N:, :, :]\n",
    "    filtered_image[:, :N, :] = peeled_image[:, :N, :]\n",
    "    filtered_image[:, -N:, :] = peeled_image[:, -N:, :]\n",
    "    \n",
    "    filtered_image = torch.clamp(filtered_image, 0, 255)\n",
    "    return filtered_image\n",
    "\n",
    "def optimize_sigma_lms(original_image, noisy_image, initial_sigma=16, learning_rate=0.01, max_iterations=500, window_size=3):\n",
    "    \"\"\"\n",
    "    Optimize the sigma parameter for the fuzzy Gaussian weighting function using LMS with PyTorch.\n",
    "    \n",
    "    Parameters:\n",
    "    - original_image: Original clean image (H x W x 3 numpy array, RGB).\n",
    "    - noisy_image: Noisy input image (H x W x 3 numpy array, RGB).\n",
    "    - initial_sigma: Initial value for sigma.\n",
    "    - learning_rate: Step size for gradient descent.\n",
    "    - max_iterations: Maximum number of iterations for LMS.\n",
    "    - window_size: Size of the local neighborhood (default 3).\n",
    "    \n",
    "    Returns:\n",
    "    - optimal_sigma: Optimized sigma value.\n",
    "    \"\"\"\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    original_tensor = torch.tensor(original_image, dtype=torch.float32)\n",
    "    noisy_tensor = torch.tensor(noisy_image, dtype=torch.float32)\n",
    "\n",
    "    \n",
    "    # Define sigma as a learnable parameter\n",
    "    sigma = torch.nn.Parameter(torch.tensor(float(initial_sigma), dtype=torch.float32))\n",
    "\n",
    "    \n",
    "    optimizer = torch.optim.AdamW([sigma], lr=learning_rate)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Apply hybrid filter to get s_{i,j} (filtered_image)\n",
    "        filtered_image = hybrid_filter_pytorch(noisy_tensor, window_size=3, threshold=50, sigma=sigma)\n",
    "        \n",
    "        # Calculate MSE between original_image (x_{i,j}) and filtered_image (s_{i,j})\n",
    "        mse = torch.mean((original_tensor - filtered_image)**2)\n",
    "        \n",
    "        # Compute gradients and update sigma\n",
    "        mse.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Ensure sigma remains positive\n",
    "        with torch.no_grad():\n",
    "            sigma.clamp_(min=1e-6)\n",
    "        \n",
    "        # Print progress\n",
    "        if iteration % 50 ==0:\n",
    "            print(f\"Iteration {iteration}, Sigma: {sigma.item():.4f}, MSE: {mse.item():.4f}\")\n",
    "        \n",
    "        # Early stopping if MSE change is small\n",
    "        if iteration > 0 and abs(mse.item() - prev_mse) < 1e-6:\n",
    "            print(f\"Converged at iteration {iteration}\")\n",
    "            break\n",
    "        \n",
    "        prev_mse = mse.item()\n",
    "    \n",
    "    return sigma.item()\n",
    "\n",
    "# Example usage (to be run after uploading images)\n",
    "if global_original_image is None or global_noisy_image is None:\n",
    "    print('Please upload both original and noisy images using the interactive interface!')\n",
    "else:\n",
    "    optimal_sigma = optimize_sigma_lms(global_original_image, global_noisy_image)\n",
    "    print(f\"Optimal Sigma: {optimal_sigma:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
